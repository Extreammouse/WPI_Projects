{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import kagglehub\n",
    "\n",
    "from datasets import load_dataset, DatasetDict, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle datasets\n",
    "\n",
    "manifest = json.load(open('Datasets/manifest.json'))\n",
    "\n",
    "for target in manifest['targets']:\n",
    "    if(not os.path.isdir(f'Datasets/{target}')):\n",
    "        path = kagglehub.dataset_download(target)\n",
    "        user = target.split('/')[0]\n",
    "        os.makedirs(f'Datasets/{user}', exist_ok=True) # Create user directory\n",
    "        os.rename(path, f'Datasets/{target}')\n",
    "    if (target == \"mbkinaci/fruit-images-for-object-detection\") and not os.path.exists('Datasets\\\\mbkinaci\\\\fruit-images-for-object-detection\\\\rectified.txt'):\n",
    "        root = \"Datasets\\\\mbkinaci\\\\fruit-images-for-object-detection\"\n",
    "        classes = ['Apple', 'Banana', 'Orange']\n",
    "        os.makedirs(f'{root}\\\\train')\n",
    "        os.makedirs(f'{root}\\\\test')\n",
    "        for name in classes:\n",
    "            os.makedirs(f'{root}\\\\train\\\\{name}')\n",
    "            os.makedirs(f'{root}\\\\test\\\\{name}')\n",
    "        for file in os.listdir(f'{root}\\\\train_zip\\\\train'):\n",
    "            if '.jpg' in file and 'mixed' not in file:\n",
    "                label = file.split('_', 1)[0].capitalize()\n",
    "                shutil.move(f'{root}\\\\train_zip\\\\train\\\\{file}', f'{root}\\\\train\\\\{label}\\\\{file}')\n",
    "        for file in os.listdir(f'{root}\\\\test_zip\\\\test'):\n",
    "            if '.jpg' in file and 'mixed' not in file:\n",
    "                label = file.split('_', 1)[0].capitalize()\n",
    "                shutil.move(f'{root}\\\\test_zip\\\\test\\\\{file}', f'{root}\\\\test\\\\{label}\\\\{file}')\n",
    "        open('Datasets\\\\mbkinaci\\\\fruit-images-for-object-detection\\\\rectified.txt', 'a').close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huggingface synthetic datasets\n",
    "\n",
    "dataset_name = \"DiegoP-S/DatasetSynthesis\"\n",
    "\n",
    "# Load the dataset from the Hub\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "# Specify the output directory where images will be saved\n",
    "output_dir = f\"Datasets/{dataset_name}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for split in dataset.keys():\n",
    "    # Extract the image data and file names\n",
    "    image_data = dataset[split][\"image\"]  # List of image binary data\n",
    "    file_names = dataset[split][\"file_name\"]  # List of file names (e.g., 'apple.png')\n",
    "\n",
    "    # Save the images locally\n",
    "    for file_name, img_data in zip(file_names, image_data):\n",
    "        if img_data:  # Only save if the image data exists\n",
    "            try:\n",
    "                # Construct the output file path\n",
    "                file_path = output_dir + '/' + split + '/' + file_name\n",
    "                os.makedirs(f'{output_dir}/{split}', exist_ok=True)\n",
    "                \n",
    "                # Write the binary image data to the file\n",
    "                with open(file_path, \"wb\") as img_file:\n",
    "                    img_file.write(img_data)\n",
    "                \n",
    "                # print(f\"Saved: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving {file_name}: {e}\")\n",
    "        else:\n",
    "            print(f\"Skipping {file_name} due to missing image data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create splits DONE\n",
    "\n",
    "# Move apple, orange, banana (synthetic) into respective apple, orange, banana folder\n",
    "# For real apple orange and banana, \"clean\" images (rescale to 512 by 512) amd move into folder\n",
    "# Apply filters to images to enhance existing dataset?\n",
    "\n",
    "## TODO: Finish generating 100 fruits\n",
    "## Generate 100 of each animal\n",
    "## Once final presentation, dig deeper into each animal.\n",
    "\n",
    "# Next cells are to restructure huggingface splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_names_copy = set()\n",
    "# for file_name in file_names:\n",
    "#     if(file_name == \"null.png\"):\n",
    "#         continue\n",
    "#     split_name, file_name = file_name.split(\"_\", 1)\n",
    "#     file_names_copy.add(split_name)\n",
    "\n",
    "# print(file_names_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize dictionaries for the new splits\n",
    "# splits = {s: {\"image\": [], \"group\": [], \"file_name\": []} for s in file_names_copy}\n",
    "\n",
    "# print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(splits[\"Banana\"][\"group\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parse the file paths and reorganize\n",
    "# for item in dataset[\"train\"]:  # Assuming everything is in the \"test\" split\n",
    "#     file_path = item[\"file_name\"]  # Adjust based on your column name\n",
    "#     if(file_path == \"null.png\"):\n",
    "#         continue\n",
    "#     split_name, file_name = file_path.split(\"_\", 1)  # Split into split and file name\n",
    "    \n",
    "#     # Add to the appropriate split\n",
    "#     # splits[split_name][\"image\"] = item[\"image\"]\n",
    "#     splits[split_name][\"group\"].append(item[\"group\"])\n",
    "#     print(len(splits[split_name][\"file_name\"]))\n",
    "#     splits[split_name][\"file_name\"].append(item[\"file_name\"])\n",
    "#     splits[split_name][\"image\"].append(item[\"image\"])\n",
    "#     print(len(splits[split_name][\"file_name\"]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace spaces with underscores in the split names\n",
    "# splits = {split_name.replace(\" \", \"_\"): data for split_name, data in splits.items()}\n",
    "# dataset = DatasetDict({split_name: Dataset.from_dict(data) for split_name, data in splits.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.push_to_hub(\"DiegoP-S/DatasetSynthesis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
